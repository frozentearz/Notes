### 一、使用 CentOS 搭建集群

##### 1. 下载 **CentOS 6.5**

>   链接:  https://pan.baidu.com/s/1QyqhSgxyLxwnwlCNf1T6Vw  
>
>   提取码:  `xq6n`

##### 2. 下载安装虚拟机

>   链接:  https://pan.baidu.com/s/197EAdLMASEcS-c_MrHmtEg 
>
>   提取码: `sger`

##### 3. 安装 CentOS 系统

##### 4. 在 VM 中修改 虚拟机网络

-   重新设置一个 nat 网络，并设置网关，子网掩码和内网 IP

    >   删除 VMnet8 重新添加一个 VMnet8 网络，并修改为 nat 模式

-   刷新虚拟机的网络模式

    >设置为桥接再设置回 nat 模式

-   修改网络配置

    >   编辑  `/etc/sysconfig/network-scripts/ifcfg-eth0`
    >
    >   ```shell
    >   DEVICE="eth0"
    >   BOOTPROTO="static" # 改成静态IP的地址
    >   NM_CONTROLLED="yes" 
    >   ONBOOT="yes"
    >   TYPE="Ethernet"
    >   IPADDR=192.168.183.10 # 配置本机静态IP
    >   NETMASK=255.255.255.0 # 掩码
    >   GATEWAY=192.168.183.2 # 网关
    >   DNS1=202.96.128.86 # DNS 这个是广东联通的IP
    >   ```

-   重启网络服务

    >   `/etc/init.d/network restart`

-   使用终端连接虚拟机

-   把系统复制多份，配置静态 IP， 重启网络服务

---

#### 二、搭建 Hadoop 环境

##### 1. 安装 jdk 

>   hadoop 依赖 java 环境

-   去官网下载对应版本的 jdk 安装好。

-   配置环境变量，用文本编辑器打开 `/etc/profile` ，并在末尾加入：

    >```shell
    >export JAVA_HOME=/opt/java/jdk1.8.0_221 
    >export PATH=$JAVA_HOME/bin:$PATH 
    >export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 
    >```

##### 2. 安装 hadoop

-   1.x 版本安装

    -   下载 1.x 版本的 hadoop

        >   链接:  https://pan.baidu.com/s/19t5noukLJPv2bIP7f0aG9A 
        >
        >   提取码:  `hbhq`

    -   解压安装到目标目录

    -   在目录下新建 `/tmp` 文件夹

    -   修改目录下 `/conf` 目录下的 `masters` ，添加：

        >   ```shell
        >   master
        >   ```

    -    修改目录下 `/conf` 目录下的 `slaves` ，添加：

        >   ```shell
        >   slave1
        >   slave2
        >   ```

    -   修改 `conf/core-site.xml` 文件，在 ` configuration` 节点下加入：

        >   ```xml
        >   <property>
        >       <name>hadoop.tmp.dir</name>
        >       <value>{刚刚创建的tmp路径}</value>
        >   </property>
        >   <property>
        >       <name>fs.default.name</name>
        >       <value>hdfs://localhost:9000</value>
        >   </property> 
        >   ```

    -   修改 `conf/mapred-site.xml` 文件，在 ` configuration` 节点下加入：

        >   ```xml
        >   <property>
        >       <name>mapred.job.tracker</name>
        >       <value>http://localhost:9001</value>
        >   </property> 
        >   ```

    -   修改 `conf/hdfs-site.xml` 文件，在 ` configuration` 节点下加入：

        >   ```xml
        >   <property>
        >       <name>dfs.replication</name>
        >       <value>3</value>
        >   </property> 
        >   ```

    -   修改 `conf/hadoop.env.sh` 文件：

        >   ```shell
        >   export JAVA_HOME={java_home}
        >   ```

-   2.x 版本安装（待补充）

##### 3. 节点互联

-   在每台机器的 `/etc/hosts` 文件中添加主从节点的对应 IP
    
    >[主节点IP] master
    >
    >[从节点1IP] slave1
    >
    >[从节点2IP] slave2
    >
    >...
-   在每台机器的 `/etc/sysconfig/network` 文件中修改 `HOSTNAME` 为角色节点名

-   各机器 关闭防火墙

    >   ```shell
    >   /etc/init.d/iptables stop
    >   iptables -L # 查看防火墙信息
    >   ```

-   设置 `selinux` 

    >   ```shell
    >   setenforce 0 # 应该是类似关闭 selinux 的命令
    >   getenforce # 查看 selinux 状态 —— Permissive
    >   ```

-    每台机器 `ssh-keygen` 生成 ssh 密钥，把 `id_rsa.pub` 公钥复制给其他机器的 `authorized_keys`  

-   启动 **hadoop**

    >   ```shell
    >   ./hadoop namenode -format # 格式化
    >   ./start-all.sh # 启动
    >   jps # 查看状态
    >   ```

-   hadoop 基础使用

    >   ```shell
    >   ./hadoop fs -ls / # 查看仓库中的目录与文件
    >   ./hadoop fs -put /etc/passwd / # 推送passwd文件到仓库中
    >   ```

