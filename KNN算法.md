## KNN 算法

![eg_knn](https://steemitimages.com/DQmP5uGgRQWaQT4sCToVEBqVnfVkcKqJihHGEbzDMPDFpU9/2012-10-26-knn-concept.png)  

>如图，现在在图中心有一未知点，用**红色五角星**标注。 
已知此点属于黄色(**Class A**)或紫色(**Class B**)的其中一种，根据全图黄色点与紫色点在全图的分布位置， 
求中心未知点是 **Class A** 还是 **Class B**？  

KNN 算法 （K-近邻算法）通过测量不同特征值之间的距离进行分类。 
KNN 算法中有一个 K 值，意为取 K 个最近元素，**哪种种类多，未知点就预判为哪种种类。**  

>如上图， 
K=3 时，最近距离中（内圈中）的三个元素有两个是 Class B（紫色点），即预判未知点为 Class B；
K=6 时，最近距离中（外圈中）的六个元素有四个是 Class A（黄色点），两个是 Class B（紫色点），即预判未知点为 Class A。 
由此也说明了KNN算法的结果很大程度取决于K的选择。

但是，确定 K 的值之后，假设 K = 3。 怎么才能知道图片中哪 k(=3) 个点是距离未知点最近的点呢？
在 KNN 中，通过计算对象间距离来作为各个对象之间的非相似性指标， 
避免了对象之间的匹配问题，在这里距离一般使用L1距离(曼哈顿距离)或L2距离(欧式距离/欧几里得距离)，使用L1或L2距离计算最近的K(=3)个点。
![](https://images0.cnblogs.com/blog2015/771535/201508/041625523458191.jpg)  
[ps:详情了解L1与L2距离](https://blog.csdn.net/zouxy09/article/details/24971995)  

KNN 算法全部步骤如下：  
>1. 计算测试数据与各个训练数据之间的距离；  
2. 按照距离的递增关系进行排序；  
3. 选取距离最小的K个点；  
4. 确定前K个点所在类别的出现频率；  
5. 返回前K个点中出现频率最高的类别作为测试数据的预测分类。  